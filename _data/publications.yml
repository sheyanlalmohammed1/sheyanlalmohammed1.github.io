main:

  - title: Bayesian and Dynamic Bayesian Networks for Credit Risk Modeling in Buy Now, Pay Later
    authors: <strong>Sheyan Lalmohammed</strong>, Paul Sabin* (*Advisor)
    conference_short: BN-DBN BNPL
    conference: Final Thesis - Wharton Research Scholars <strong>(WRS)</strong>, 2025.
    abstract: This paper investigates the application of Bayesian Networks (BNs) and Dynamic Bayesian Networks (DBNs) on personalized credit risk assessment in the Buy Now, Pay Later (BNPL) industry. Using data from the Lending Club as a proxy for BNPL loans, the paper constructs multiple static and 5-period temporal network structures by discretizing borrower, loan, and macroeconomic characteristics. The use of score-based structure-learning methods allows for the identification of optimal network structures.  A cost-sensitive bootstrap evaluation assesses model performance across multiple classification metrics. Results show that naive BNs offer high interpretability, BNs with learned structures capture important inter-dependencies in the data, and DBNs provide improved temporal inference, all while remaining computationally efficient for real-time decision making for a BNPL context. The findings suggest that using these models can serve effectively as a secondary check for default prediction flexible to the needs of the lender, balancing risk and operational constraints in short-term lending.
    pdf: assets/files/Final Thesis - Sheyan Lalmohammed.pdf
    code: https://github.com/sheyanlalmohammed1
    page: https://repository.upenn.edu/exhibits/orgunit/wharton_research_scholars
    image: assets/img/BN-DBN BNPL.png

  - title: Modeling Human Behavior Without Humans – Bringing Prospect Theory to Multi-Agent Reinforcement Learning
    authors: Sheyan Lalmohammed, Khush Gupta, ALok Shah, Keshav Ramji, Damek Davis* (*Advisor)
    conference_short: CPT-MARL
    conference: Numerical Optimization for Machine Learning and Data Science - Final Project <strong>(STAT 4830)</strong>, 2025.
    abstract: We apply CPT-MADDPG, a novel extension of the Multi-Agent Deep Deterministic Policy Gradient algorithm that embeds full Cumulative Prospect Theory (CPT) value and probability-weighting transforms into both critic and actor updates. By replacing expected-return maximization with rank-dependent Choquet integrals over gains and losses, CPT-MADDPG endows agents with tunable risk profiles—ranging from exploratory, risk-seeking behaviors to conservative, loss-averse ones—without human intervention. We further propose two extensions: an observability adjustment, which aggregates cross-agent subjective utilities in the Bellman backup when agents share CPT parameters; and adaptive behavioral parameters, where CPT hyperparameters are learned online via a secondary loss. Across competitive pursuit (Simple Tag), cooperative coverage (Simple Spread), and strategic bidding (first-price auctions), we show that risk-seeking parameterized CPT speeds early learning, extreme risk-averse parameterized CPT enforces prudence at a performance cost, transparent utility sharing preserves coordination under heterogeneity, and naive dynamic adaptation destabilizes convergence. In auction settings, learned CPT policies replicate the overbidding phenomenon documented by Josheski and Delcev, yielding short-term gains followed by long-term losses. Our work demonstrates a principled, differentiable framework for integrating human-like risk attitudes into multi-agent RL.
    pdf: assets/files/CPT-MARL.pdf
    code: https://github.com/sheyanlalmohammed1/STAT-4830-CPT-MARL-project
    page: https://github.com/sheyanlalmohammed1/STAT-4830-CPT-MARL-project
    image: assets/img/CPT-MARL.png

  - title: "Mnemonics Training: Multi-Class Incremental Learning without Forgetting"
    authors: Sheyan Lalmohammed, Khush Gupta, ALok Shah, Keshav Ramji
    conference_short: CPT-MARL
    conference: Numerical Optimization for Machine Learning and Data Science - Final Project <strong>(STAT 4830)</strong>, 2025.
    abstract: We apply CPT-MADDPG, a novel extension of the Multi-Agent Deep Deterministic Policy Gradient algorithm that embeds full Cumulative Prospect Theory (CPT) value and probability-weighting transforms into both critic and actor updates. By replacing expected-return maximization with rank-dependent Choquet integrals over gains and losses, CPT-MADDPG endows agents with tunable risk profiles—ranging from exploratory, risk-seeking behaviors to conservative, loss-averse ones—without human intervention. We further propose two extensions: an observability adjustment, which aggregates cross-agent subjective utilities in the Bellman backup when agents share CPT parameters; and adaptive behavioral parameters, where CPT hyperparameters are learned online via a secondary loss. Across competitive pursuit (Simple Tag), cooperative coverage (Simple Spread), and strategic bidding (first-price auctions), we show that risk-seeking parameterized CPT speeds early learning, extreme risk-averse parameterized CPT enforces prudence at a performance cost, transparent utility sharing preserves coordination under heterogeneity, and naive dynamic adaptation destabilizes convergence. In auction settings, learned CPT policies replicate the overbidding phenomenon documented by Josheski and Delcev, yielding short-term gains followed by long-term losses. Our work demonstrates a principled, differentiable framework for integrating human-like risk attitudes into multi-agent RL.
    pdf: assets/files/CPT-MARL.pdf
    code: https://github.com/sheyanlalmohammed1/STAT-4830-CPT-MARL-project
    page: https://class-il.mpi-inf.mpg.de/mnemonics/
    bibtex: https://class-il.mpi-inf.mpg.de/mnemonics/
    notes: Oral Presentation
    image: ./assets/img/teaser_example.png
